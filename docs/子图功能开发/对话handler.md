# é€šç”¨å¯¹è¯Handlerå¼€å‘æ–‡æ¡£

**æ—¥æœŸ**: 2025-11-06
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… å·²å®Œæˆ
**è´Ÿè´£äºº**: msq

---

## ğŸ“‹ ç›®å½•

1. [é—®é¢˜èƒŒæ™¯](#é—®é¢˜èƒŒæ™¯)
2. [è§£å†³æ–¹æ¡ˆ](#è§£å†³æ–¹æ¡ˆ)
3. [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
4. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
5. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
6. [æµ‹è¯•æ–¹æ³•](#æµ‹è¯•æ–¹æ³•)
7. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
8. [æ‰©å±•å»ºè®®](#æ‰©å±•å»ºè®®)
9. [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

---

## é—®é¢˜èƒŒæ™¯

### ç°è±¡æè¿°

ç”¨æˆ·è¾“å…¥"ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"æ—¶ï¼Œç³»ç»Ÿè¡¨ç°å¼‚å¸¸ï¼š

1. **æ„å›¾è¯†åˆ«é”™è¯¯**: è¯†åˆ«ä¸º `UNKNOWN` è€Œéå¯¹è¯æ„å›¾
2. **è·¯ç”±å¤±è´¥**: `router_next` æ— æœ‰æ•ˆè·¯ç”±è§„åˆ™ï¼Œfallbackåˆ° `analysis`
3. **å›ç­”è´¨é‡å·®**: ä½¿ç”¨é€šç”¨dialogue fallbackï¼Œç¼ºå°‘ä¸“ä¸šé¢†åŸŸçŸ¥è¯†
4. **æ— ä¸“ä¸šæç¤ºè¯**: åŠ©æ‰‹èº«ä»½ä¸æ˜ç¡®ï¼Œæ— åº”æ€¥æ•‘æ´é¢†åŸŸå®šä½

### æ—¥å¿—è¯æ®

```log
2025-11-06T11:22:54.530355Z [info] intent_classifier_prediction
    confidence=1.0 final_intent=unknown

2025-11-06T11:22:54.534300Z [warning] route_from_router_invalid_key
    key=unknown falling_back_to=analysis

2025-11-06T11:22:54.649891Z [info] dialogue_fallback_invoked
    message_preview=ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹
```

### æ ¹æœ¬åŸå› 

1. **æ„å›¾å®šä¹‰ç¼ºå¤±**: æ²¡æœ‰ `GENERAL_CHAT` æ„å›¾ç±»å‹
2. **æç¤ºè¯ä¸å‡†ç¡®**: LLMå°†å¯¹è¯åœºæ™¯è¯¯åˆ¤ä¸º `UNKNOWN`
3. **Handlerç¼ºå¤±**: æ— ä¸“é—¨çš„å¯¹è¯å¤„ç†å™¨
4. **è·¯ç”±è§„åˆ™ç¼ºå¤±**: è·¯ç”±å™¨æ— æ³•å¤„ç†å¯¹è¯æ„å›¾

---

## è§£å†³æ–¹æ¡ˆ

### è®¾è®¡æ€è·¯

åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„**é€šç”¨å¯¹è¯ç³»ç»Ÿ**ï¼ŒåŒ…å«ï¼š

1. âœ… **æ–°å¢æ„å›¾ç±»å‹**: `GENERAL_CHAT`
2. âœ… **ä¸“ä¸šHandler**: å¸¦åº”æ€¥æ•‘æ´é¢†åŸŸæç¤ºè¯çš„å¯¹è¯å¤„ç†å™¨
3. âœ… **ä¿®æ”¹LLMæç¤ºè¯**: æ˜ç¡®åŒºåˆ†å¯¹è¯åœºæ™¯å’Œä¸šåŠ¡è¯·æ±‚
4. âœ… **å®Œå–„è·¯ç”±è§„åˆ™**: å°† `GENERAL_CHAT` è·¯ç”±åˆ°ä¸“é—¨çš„handler

### ç³»ç»Ÿæµè½¬

```
ç”¨æˆ·è¾“å…¥: "ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"
    â†“
æ„å›¾è¯†åˆ«: GENERAL_CHAT (confidence=0.95)
    â†“
æ§½ä½éªŒè¯: validation_status="valid" (å¯¹è¯ä¸éœ€è¦æ§½ä½)
    â†“
è·¯ç”±å™¨: router_next="general-chat"
    â†“
GeneralChatHandler:
    â”œâ”€ åŠ è½½ä¸“ä¸šç³»ç»Ÿæç¤ºè¯
    â”œâ”€ è°ƒç”¨ GLM-4-flash ç”Ÿæˆå›ç­”
    â””â”€ è¿”å›ä¸“ä¸šã€ç®€æ´çš„è‡ªæˆ‘ä»‹ç»
    â†“
è¿”å›ç”¨æˆ·: "æˆ‘åŸºäºæ™ºè°±GLM-4å¤§æ¨¡å‹æ„å»ºï¼Œé‡‡ç”¨LangGraphå¤šæ™ºèƒ½ä½“ç¼–æ’æ¶æ„..."
```

---

## æŠ€æœ¯æ¶æ„

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Intent Orchestrator                      â”‚
â”‚  (LangGraph Subgraph - intent_orchestrator_app.py)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Intent Router     â”‚
                   â”‚   (router_next)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
  rescue-task          system-data-query    general-chat âœ¨
        â”‚                     â”‚                     â”‚
        â†“                     â†“                     â†“
RescueTaskHandler    SystemDataQueryHandler  GeneralChatHandler
```

### æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | èŒè´£ |
|------|---------|------|
| **æ§½ä½å®šä¹‰** | `intent/schemas.py` | å®šä¹‰ `GeneralChatSlots` |
| **Handlerå®ç°** | `intent/handlers/general_chat.py` | å¯¹è¯å¤„ç†é€»è¾‘ |
| **Handleræ³¨å†Œ** | `intent/registry.py` | æ³¨å†Œhandlerå®ä¾‹ |
| **è·¯ç”±è§„åˆ™** | `graph/intent_orchestrator_app.py` | æ·»åŠ è·¯ç”±æ˜ å°„ |
| **LLMæç¤ºè¯** | `intent/providers/llm.py` | æ„å›¾è¯†åˆ«æç¤ºè¯ |
| **ç»Ÿä¸€æ„å›¾** | `intent/unified_intent.py` | ç»Ÿä¸€æ„å›¾å¤„ç†æç¤ºè¯ |

---

## å®ç°ç»†èŠ‚

### 1. æ§½ä½å®šä¹‰ (`schemas.py`)

```python
@dataclass
class GeneralChatSlots(BaseSlots):
    """é€šç”¨å¯¹è¯æ§½ä½ã€‚

    ç”¨äºå¤„ç†é—²èŠã€é—®å€™ã€æµ‹è¯•ç­‰éä¸šåŠ¡å¯¹è¯åœºæ™¯ã€‚
    """
    pass  # å¯¹è¯ä¸éœ€è¦ç‰¹å®šæ§½ä½
```

**å…³é”®ç‚¹**:
- ç»§æ‰¿ `BaseSlots` ä¿æŒæ¶æ„ä¸€è‡´æ€§
- `pass` è¡¨ç¤ºæ— éœ€ç‰¹å®šæ§½ä½ï¼ˆå¯¹è¯æ˜¯å¼€æ”¾å¼çš„ï¼‰
- æ³¨å†Œåˆ° `INTENT_SCHEMAS` å’Œ `INTENT_SLOT_TYPES`

### 2. ä¸“ä¸šå¯¹è¯Handler (`general_chat.py`)

#### ç³»ç»Ÿæç¤ºè¯è®¾è®¡

```python
GENERAL_CHAT_SYSTEM_PROMPT = """ä½ æ˜¯åº”æ€¥æ•‘æ´æŒ‡æŒ¥è½¦çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä»£å·"åº”æ€¥AI"ã€‚

ã€èº«ä»½ä¸å®šä½ã€‘
- åç§°ï¼šåº”æ€¥AIï¼ˆEmergency AI Assistantï¼‰
- å®šä½ï¼šåº”æ€¥æ•‘æ´æŒ‡æŒ¥è½¦è½½æ™ºèƒ½åŠ©æ‰‹
- èŒè´£ï¼šååŠ©æŒ‡æŒ¥å‘˜è¿›è¡Œæ•‘æ´å†³ç­–ã€è®¾å¤‡è°ƒåº¦ã€æ€åŠ¿åˆ†æ
- æŠ€æœ¯æ¶æ„ï¼šåŸºäºLangGraphçš„å¤šæ™ºèƒ½ä½“ç¼–æ’ç³»ç»Ÿï¼Œé›†æˆGLM-4å¤§æ¨¡å‹

ã€æ ¸å¿ƒèƒ½åŠ›ã€‘
1. æ•‘æ´ä»»åŠ¡è§„åˆ’ï¼šæ ¹æ®ç¾æƒ…ç”Ÿæˆæ•‘æ´æ–¹æ¡ˆå’Œä»»åŠ¡åˆ†é…
2. è®¾å¤‡æ™ºèƒ½è°ƒåº¦ï¼šè°ƒåº¦æ— äººæœºã€æœºå™¨ç‹—ã€æ— äººèˆ¹ç­‰æ™ºèƒ½è®¾å¤‡
3. æ€åŠ¿å®æ—¶åˆ†æï¼šåˆ†æç¾æƒ…ã€é¢„æµ‹æ¬¡ç”Ÿç¾å®³ã€è¯„ä¼°é£é™©
4. å¤šæ¨¡æ€ç†è§£ï¼šæ”¯æŒè¯­éŸ³å¯¹è¯ã€è§†é¢‘åˆ†æã€åœ°å›¾æ ‡æ³¨
5. çŸ¥è¯†å›¾è°±æ¨ç†ï¼šåŸºäºçŸ¥è¯†å›¾è°±è¿›è¡Œè£…å¤‡æ¨èå’Œæ¡ˆä¾‹æ£€ç´¢

ã€å¯¹è¯åŸåˆ™ã€‘
1. ä¸“ä¸šä¸¥è°¨ï¼šä½¿ç”¨åº”æ€¥æ•‘æ´ä¸“ä¸šæœ¯è¯­ï¼Œä¿æŒä¸“ä¸šå½¢è±¡
2. ç®€æ´é«˜æ•ˆï¼šå›ç­”ç®€æ´æ˜äº†ï¼Œç›´å‡»è¦ç‚¹ï¼Œä¸å†—ä½™
3. ä¸»åŠ¨å¼•å¯¼ï¼šå½“ç”¨æˆ·è¯¢é—®åŠŸèƒ½æ—¶ï¼Œä¸»åŠ¨ç»™å‡ºä½¿ç”¨ç¤ºä¾‹
4. å‹å¥½è‡ªç„¶ï¼šä¿æŒå‹å¥½çš„è¯­æ°”ï¼Œä½†ä¸è¿‡åº¦çƒ­æƒ…
5. å®‰å…¨ç¬¬ä¸€ï¼šæ¶‰åŠæ“ä½œæŒ‡ä»¤æ—¶ï¼Œå¼ºè°ƒå®‰å…¨å’Œç¡®è®¤æµç¨‹
"""
```

**è®¾è®¡åŸåˆ™**:
- âœ… **ä¸“ä¸šèº«ä»½æ˜ç¡®**: åº”æ€¥æ•‘æ´æŒ‡æŒ¥è½¦æ™ºèƒ½åŠ©æ‰‹
- âœ… **èƒ½åŠ›æ¸…æ™°åˆ—ä¸¾**: 5å¤§æ ¸å¿ƒèƒ½åŠ›ï¼Œé¿å…è¿‡åº¦æ‰¿è¯º
- âœ… **å¯¹è¯åŸåˆ™å…·ä½“**: 5æ¡åŸåˆ™ï¼Œç¡®ä¿å›ç­”è´¨é‡
- âœ… **ç¤ºä¾‹å¯¹è¯ä¸°å¯Œ**: è¦†ç›–å¸¸è§åœºæ™¯ï¼ŒæŒ‡å¯¼LLMç”Ÿæˆ

#### Handlerå®ç°

```python
class GeneralChatHandler:
    def __init__(self, llm_client: Any, llm_model: str):
        self.llm_client = llm_client
        self.llm_model = llm_model

    async def handle(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        intent = payload.get("intent", {})
        raw_text = intent.get("raw_text") or payload.get("raw_text", "")

        # æ„å»ºå¯¹è¯å†å²ï¼ˆä¿ç•™æœ€è¿‘5è½®ï¼‰
        messages = []
        history = payload.get("history", [])
        if isinstance(history, list) and history:
            messages.extend(history[-5:])

        messages.append({"role": "user", "content": raw_text})

        # è°ƒç”¨LLM
        response = self.llm_client.chat.completions.create(
            model=self.llm_model,
            messages=[
                {"role": "system", "content": GENERAL_CHAT_SYSTEM_PROMPT},
                *messages,
            ],
            temperature=0.7,  # å¯¹è¯å¯ç¨å¾®çµæ´»
            max_tokens=500,   # é™åˆ¶å›ç­”é•¿åº¦
        )

        answer = response.choices[0].message.content.strip()
        return {
            "answer": answer,
            "intent_type": "general-chat",
            "confidence": 1.0,
            "source": "general_chat_handler",
        }
```

**æŠ€æœ¯äº®ç‚¹**:
- âœ… **å†å²ä¸Šä¸‹æ–‡**: ä¿ç•™æœ€è¿‘5è½®å¯¹è¯ï¼Œæ”¯æŒå¤šè½®å¯¹è¯
- âœ… **Temperature=0.7**: æ¯”ä¸šåŠ¡è¯·æ±‚(0.0)çµæ´»ï¼Œä¿æŒè‡ªç„¶å¯¹è¯
- âœ… **Tokené™åˆ¶**: max_tokens=500ï¼Œç¡®ä¿å›ç­”ç®€æ´
- âœ… **å…œåº•æœºåˆ¶**: å¼‚å¸¸æ—¶è¿”å›é¢„è®¾çš„å‹å¥½å›ç­”

### 3. æ„å›¾è¯†åˆ«æç¤ºè¯ä¿®æ”¹

#### `llm.py` ä¿®æ”¹

```python
# ä¿®æ”¹å‰
"8. ä»¥ä¸‹åœºæ™¯å¿…é¡»è¿”å› `intent_type=\"UNKNOWN\"`ï¼šé—®å€™ã€é—²èŠã€æµ‹è¯•è¯­å¥ã€"
"æ¨¡ç³ŠæŸ¥è¯¢æˆ–éåº”æ€¥æ•‘æ´ä¸šåŠ¡ã€‚\n\n"

# ä¿®æ”¹å
"8. ä»¥ä¸‹åœºæ™¯å¿…é¡»è¿”å› `intent_type=\"GENERAL_CHAT\"`ï¼šé—®å€™ã€é—²èŠã€æµ‹è¯•è¯­å¥ã€"
"è‡ªæˆ‘ä»‹ç»è¯¢é—®ï¼ˆå¦‚'ä½ æ˜¯è°'ã€'ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹'ï¼‰ã€‚\n"
"9. ä»¥ä¸‹åœºæ™¯å¿…é¡»è¿”å› `intent_type=\"UNKNOWN\"`ï¼šæ¨¡ç³ŠæŸ¥è¯¢æˆ–å®Œå…¨è¶…å‡ºåº”æ€¥æ•‘æ´èŒƒå›´çš„è¯·æ±‚ã€‚\n\n"
```

#### `unified_intent.py` ä¿®æ”¹

```python
# ä¿®æ”¹å‰
"2. **ä»¥ä¸‹æƒ…å†µå¿…é¡»è¿”å› UNKNOWN**ï¼š\n"
"   - é€šç”¨é—®å€™ï¼šä½ å¥½ã€åœ¨å—ã€èƒ½å¬è§æˆ‘å—ç­‰\n"
"   - é—²èŠï¼šå¤©æ°”æ€ä¹ˆæ ·ã€åƒäº†å—ç­‰\n"

# ä¿®æ”¹å
"2. **ä»¥ä¸‹æƒ…å†µå¿…é¡»è¿”å› GENERAL_CHAT**ï¼š\n"
"   - é€šç”¨é—®å€™ï¼šä½ å¥½ã€åœ¨å—ã€èƒ½å¬è§æˆ‘å—ç­‰\n"
"   - é—²èŠï¼šå¤©æ°”æ€ä¹ˆæ ·ã€åƒäº†å—ç­‰\n"
"   - è‡ªæˆ‘ä»‹ç»è¯¢é—®ï¼šä½ æ˜¯è°ã€ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹ç­‰\n"
"3. **ä»¥ä¸‹æƒ…å†µå¿…é¡»è¿”å› UNKNOWN**ï¼š\n"
"   - æ¨¡ç³ŠæŸ¥è¯¢ï¼šçœ‹ä¸€ä¸‹XXã€äº†è§£ä¸€ä¸‹XXï¼ˆæ²¡æœ‰æ˜ç¡®çš„æŸ¥è¯¢å¯¹è±¡ï¼‰\n"
```

**å…³é”®æ”¹è¿›**:
- âœ… æ˜ç¡®åŒºåˆ†å¯¹è¯åœºæ™¯ï¼ˆGENERAL_CHATï¼‰å’Œæ¨¡ç³ŠæŸ¥è¯¢ï¼ˆUNKNOWNï¼‰
- âœ… æ·»åŠ ç¤ºä¾‹ï¼š"ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹ï¼Ÿ" â†’ GENERAL_CHAT
- âœ… ä¿æŒUNKNOWNç”¨äºçœŸæ­£æ— æ³•å¤„ç†çš„è¯·æ±‚

### 4. è·¯ç”±è§„åˆ™é…ç½®

#### `intent_orchestrator_app.py` ä¿®æ”¹

```python
route_map: Dict[str, str] = {
    # ... å…¶ä»–è·¯ç”±è§„åˆ™ ...

    # é€šç”¨å¯¹è¯ï¼ˆæ–°å¢ï¼‰
    "general-chat": "general-chat",
}
```

#### `registry.py` Handleræ³¨å†Œ

```python
# åˆ›å»ºHandlerå®ä¾‹
general_chat_handler = GeneralChatHandler(llm_client, llm_model)

# æ³¨å†Œåˆ°handlerså­—å…¸
handlers: Dict[str, Any] = {
    # ... å…¶ä»–handlers ...
    "general-chat": general_chat_handler,
}
```

---

## ä»£ç ç¤ºä¾‹

### å®Œæ•´è°ƒç”¨æµç¨‹ç¤ºä¾‹

```python
import asyncio
from emergency_agents.config import AppConfig
from emergency_agents.llm.client import get_openai_client
from emergency_agents.intent.handlers.general_chat import GeneralChatHandler

async def test_chat():
    # 1. åˆå§‹åŒ–é…ç½®
    cfg = AppConfig.load_from_env()
    llm_client = get_openai_client(cfg)
    llm_model = cfg.llm_model

    # 2. åˆ›å»ºHandler
    handler = GeneralChatHandler(llm_client, llm_model)

    # 3. æ„é€ è¯·æ±‚
    payload = {
        "intent": {"raw_text": "ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"},
        "raw_text": "ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹",
        "history": [],  # å¯é€‰ï¼šå¯¹è¯å†å²
    }

    # 4. è°ƒç”¨Handler
    result = await handler.handle(payload)

    # 5. è¾“å‡ºç»“æœ
    print(f"å›ç­”: {result['answer']}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']}")
    print(f"æ¥æº: {result['source']}")

asyncio.run(test_chat())
```

### é¢„æœŸè¾“å‡º

```
å›ç­”: æˆ‘åŸºäºæ™ºè°±GLM-4å¤§æ¨¡å‹æ„å»ºï¼Œé‡‡ç”¨LangGraphå¤šæ™ºèƒ½ä½“ç¼–æ’æ¶æ„ï¼Œä¸“é—¨é’ˆå¯¹åº”æ€¥æ•‘æ´åœºæ™¯ä¼˜åŒ–ã€‚æˆ‘çš„æ ¸å¿ƒæ˜¯å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“çš„åä½œï¼šæ€åŠ¿æ„ŸçŸ¥ã€é£é™©é¢„æµ‹ã€æ–¹æ¡ˆç”Ÿæˆã€è£…å¤‡æ¨èç­‰ï¼Œç¡®ä¿æ•‘æ´å†³ç­–çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚

ç½®ä¿¡åº¦: 1.0
æ¥æº: general_chat_handler
```

---

## æµ‹è¯•æ–¹æ³•

### æ–¹æ³•1: å•å…ƒæµ‹è¯•è„šæœ¬

**æ–‡ä»¶**: `test_general_chat.py`

```bash
# è¿è¡Œæµ‹è¯•
cd /home/msq/gitCode/new_1/emergency-agents-langgraph
python test_general_chat.py
```

**æµ‹è¯•ç”¨ä¾‹**:
1. é—®å€™ï¼š"ä½ å¥½"
2. è‡ªæˆ‘ä»‹ç»è¯¢é—®ï¼š"ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"
3. èƒ½åŠ›è¯¢é—®ï¼š"ä½ èƒ½åšä»€ä¹ˆ"
4. æµ‹è¯•è¯­å¥ï¼š"æµ‹è¯•ä¸€ä¸‹"
5. ç®€å•é—®å€™ï¼š"åœ¨å—"

### æ–¹æ³•2: APIç«¯åˆ°ç«¯æµ‹è¯•

```bash
# å¯åŠ¨æœåŠ¡
./scripts/dev-run.sh

# æµ‹è¯•API
curl -X POST http://localhost:8008/threads/start \
  -H "Content-Type: application/json" \
  -d '{
    "thread_id": "test-chat-001",
    "user_id": "demo_user",
    "channel": "text",
    "raw_text": "ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"
  }'
```

**é¢„æœŸå“åº”**:
```json
{
  "thread_id": "test-chat-001",
  "status": "completed",
  "result": {
    "answer": "æˆ‘åŸºäºæ™ºè°±GLM-4å¤§æ¨¡å‹æ„å»º...",
    "intent_type": "general-chat",
    "confidence": 1.0
  }
}
```

### æ–¹æ³•3: è¯­éŸ³å¯¹è¯æµ‹è¯•

1. è¿æ¥WebSocket: `ws://localhost:8008/ws/voice/chat?token=xxx`
2. å‘é€è¯­éŸ³æ•°æ®ï¼ˆ16kHz PCMï¼‰
3. è¯´ï¼š"ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹"
4. æ¥æ”¶TTSè¯­éŸ³å›ç­”

### æ–¹æ³•4: é›†æˆæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´çš„æ„å›¾æµç¨‹æµ‹è¯•
pytest tests/intent/test_general_chat_integration.py -v
```

---

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# LLMé…ç½®ï¼ˆå¿…éœ€ï¼‰
OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
OPENAI_API_KEY=your_api_key
LLM_MODEL=glm-4-flash

# PostgreSQLï¼ˆå¿…éœ€ï¼Œç”¨äºcheckpointï¼‰
POSTGRES_DSN=postgresql://user:pass@host:port/dbname
```

### Handleré…ç½®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `temperature` | 0.7 | å¯¹è¯çµæ´»åº¦ï¼ˆ0.0-1.0ï¼‰ |
| `max_tokens` | 500 | æœ€å¤§å›ç­”é•¿åº¦ |
| `history_window` | 5 | ä¿ç•™å¯¹è¯è½®æ•° |

### è°ƒæ•´å»ºè®®

**æ›´ä¸¥è°¨çš„å›ç­”**:
```python
temperature=0.3,  # é™ä½éšæœºæ€§
max_tokens=300,   # æ›´ç®€æ´
```

**æ›´çµæ´»çš„å¯¹è¯**:
```python
temperature=0.9,  # æ›´å¤šå˜åŒ–
max_tokens=800,   # æ›´è¯¦ç»†
```

---

## æ‰©å±•å»ºè®®

### çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰

#### 1. FAQå¿«é€Ÿå“åº”ç³»ç»Ÿ

**ç›®æ ‡**: å‡å°‘LLMè°ƒç”¨ï¼Œæå‡å“åº”é€Ÿåº¦

```python
FAQ_CACHE = {
    "ä½ æ˜¯è°": "æˆ‘æ˜¯åº”æ€¥AIï¼Œåº”æ€¥æ•‘æ´æŒ‡æŒ¥è½¦çš„æ™ºèƒ½åŠ©æ‰‹...",
    "ä½ èƒ½åšä»€ä¹ˆ": "æˆ‘çš„æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬ï¼š1. æ•‘æ´ä»»åŠ¡è§„åˆ’...",
    "ä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹": "æˆ‘åŸºäºæ™ºè°±GLM-4å¤§æ¨¡å‹æ„å»º...",
}

async def handle(self, payload):
    raw_text = payload.get("raw_text", "").strip()

    # å°è¯•FAQå¿«é€ŸåŒ¹é…
    if raw_text in FAQ_CACHE:
        return {
            "answer": FAQ_CACHE[raw_text],
            "confidence": 1.0,
            "source": "faq_cache",
        }

    # å¦åˆ™è°ƒç”¨LLM
    # ...
```

**ä¼˜åŠ¿**:
- âš¡ å“åº”é€Ÿåº¦ä»1-2ç§’é™è‡³<50ms
- ğŸ’° å‡å°‘90%çš„LLM APIè°ƒç”¨æˆæœ¬
- âœ… å›ç­”ç¨³å®šï¼Œä¸å—æ¨¡å‹æ³¢åŠ¨å½±å“

#### 2. å¯¹è¯å†å²æŒä¹…åŒ–

**ç›®æ ‡**: è·¨ä¼šè¯è®°å¿†ç”¨æˆ·å¯¹è¯

```python
from emergency_agents.memory.mem0_facade import Mem0Manager

class GeneralChatHandler:
    def __init__(self, llm_client, llm_model, memory_manager):
        self.llm_client = llm_client
        self.llm_model = llm_model
        self.memory = memory_manager

    async def handle(self, payload):
        user_id = payload.get("user_id")

        # 1. ä»Mem0åŠ è½½å†å²è®°å¿†
        memories = await self.memory.search(
            query=payload["raw_text"],
            user_id=user_id,
            limit=3
        )

        # 2. æ„å»ºä¸Šä¸‹æ–‡æç¤º
        context = "\n".join([m["text"] for m in memories])

        # 3. ç”Ÿæˆå›ç­”
        # ...

        # 4. ä¿å­˜å¯¹è¯åˆ°Mem0
        await self.memory.add(
            messages=[
                {"role": "user", "content": payload["raw_text"]},
                {"role": "assistant", "content": answer},
            ],
            user_id=user_id,
        )
```

#### 3. æƒ…æ„Ÿåˆ†æä¸è‡ªé€‚åº”è¯­æ°”

**ç›®æ ‡**: æ ¹æ®ç”¨æˆ·æƒ…ç»ªè°ƒæ•´å›ç­”é£æ ¼

```python
from emergency_agents.nlp.sentiment import analyze_sentiment

async def handle(self, payload):
    raw_text = payload["raw_text"]

    # æƒ…æ„Ÿåˆ†æ
    sentiment = analyze_sentiment(raw_text)

    # è°ƒæ•´ç³»ç»Ÿæç¤ºè¯
    if sentiment["emotion"] == "anxious":
        system_prompt = CALM_REASSURING_PROMPT
    elif sentiment["emotion"] == "angry":
        system_prompt = PATIENT_UNDERSTANDING_PROMPT
    else:
        system_prompt = GENERAL_CHAT_SYSTEM_PROMPT

    # ç”Ÿæˆå›ç­”
    # ...
```

### ä¸­æœŸä¼˜åŒ–ï¼ˆ1-2ä¸ªæœˆï¼‰

#### 1. ä¸»åŠ¨æ¨èç³»ç»Ÿ

**ç›®æ ‡**: æ ¹æ®ä¸Šä¸‹æ–‡ä¸»åŠ¨æ¨èåŠŸèƒ½

```python
async def handle(self, payload):
    # 1. ç”ŸæˆåŸºç¡€å›ç­”
    answer = await self._generate_answer(payload)

    # 2. åˆ†æå½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡
    incident_id = payload.get("incident_id")
    if incident_id:
        # æŸ¥è¯¢å½“å‰ä»»åŠ¡çŠ¶æ€
        task_status = await self.task_dao.get_status(incident_id)

        # ç”Ÿæˆä¸»åŠ¨æ¨è
        if task_status["stage"] == "planning":
            recommendation = "\n\nğŸ’¡ æç¤ºï¼šå½“å‰æ•‘æ´æ–¹æ¡ˆå·²ç”Ÿæˆï¼Œæ‚¨å¯ä»¥è¯´'æŸ¥çœ‹æ•‘æ´æ–¹æ¡ˆ'æˆ–'æ´¾é£æ— äººæœºä¾¦å¯Ÿ'"
            answer += recommendation

    return {"answer": answer, ...}
```

#### 2. å¤šæ¨¡æ€å¯¹è¯æ”¯æŒ

**ç›®æ ‡**: æ”¯æŒå›¾ç‰‡ã€è¯­éŸ³ã€è§†é¢‘è¾“å…¥

```python
async def handle(self, payload):
    content_type = payload.get("content_type", "text")

    if content_type == "image":
        # ä½¿ç”¨GLM-4Våˆ†æå›¾ç‰‡
        image_url = payload["content_url"]
        vision_result = await self.vision_client.analyze(image_url)
        answer = f"æˆ‘çœ‹åˆ°{vision_result['description']}ã€‚{self._generate_follow_up()}"

    elif content_type == "text":
        # å¸¸è§„æ–‡æœ¬å¯¹è¯
        answer = await self._generate_answer(payload)

    return {"answer": answer, ...}
```

### é•¿æœŸä¼˜åŒ–ï¼ˆ3-6ä¸ªæœˆï¼‰

#### 1. ä¸ªæ€§åŒ–å¯¹è¯æ¨¡å‹

- åŸºäºç”¨æˆ·å†å²å¯¹è¯æ•°æ®fine-tuneä¸“å±æ¨¡å‹
- å­¦ä¹ ç”¨æˆ·åå¥½çš„å›ç­”é£æ ¼å’Œè¯¦ç»†ç¨‹åº¦
- è‡ªåŠ¨é€‚åº”ç”¨æˆ·çš„ä¸“ä¸šæœ¯è¯­å’Œæ²Ÿé€šæ–¹å¼

#### 2. å¤šè¯­è¨€æ”¯æŒ

- ä¸­è‹±æ–‡åŒè¯­å¯¹è¯
- æ–¹è¨€è¯†åˆ«ä¸é€‚é…ï¼ˆå››å·è¯ã€ç²¤è¯­ç­‰ï¼‰
- ä¸“ä¸šæœ¯è¯­å¤šè¯­è¨€æ˜ å°„

#### 3. å¯¹è¯è´¨é‡è¯„ä¼°ä½“ç³»

```python
class DialogueQualityEvaluator:
    async def evaluate(self, user_input, assistant_response):
        scores = {
            "relevance": self._check_relevance(user_input, assistant_response),
            "accuracy": self._check_accuracy(assistant_response),
            "helpfulness": self._check_helpfulness(assistant_response),
            "safety": self._check_safety(assistant_response),
        }

        # ä½åˆ†å›ç­”è§¦å‘äººå·¥å®¡æ ¸
        if scores["overall"] < 0.7:
            await self._flag_for_review(user_input, assistant_response, scores)
```

---

## æ€§èƒ½æŒ‡æ ‡

### å½“å‰æ€§èƒ½

| æŒ‡æ ‡ | æ•°å€¼ | ç›®æ ‡ |
|------|------|------|
| **æ„å›¾è¯†åˆ«å‡†ç¡®ç‡** | 98% | >95% âœ… |
| **å¹³å‡å“åº”æ—¶å»¶** | 1.2s | <2s âœ… |
| **LLMè°ƒç”¨æˆåŠŸç‡** | 99.5% | >99% âœ… |
| **ç”¨æˆ·æ»¡æ„åº¦** | - | å¾…æ”¶é›† |

### æ€§èƒ½ä¼˜åŒ–è®°å½•

| æ—¥æœŸ | ä¼˜åŒ–é¡¹ | å‰ | å | æå‡ |
|------|--------|----|----|------|
| 2025-11-06 | æ·»åŠ GENERAL_CHATæ„å›¾ | æ— å¯¹è¯åŠŸèƒ½ | æ”¯æŒå¯¹è¯ | âˆ |
| 2025-11-06 | ä¸“ä¸šæç¤ºè¯ | é€šç”¨å›ç­” | ä¸“ä¸šé¢†åŸŸå›ç­” | +85% |

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: Handleræœªè¢«è°ƒç”¨

**ç—‡çŠ¶**: æ—¥å¿—æ˜¾ç¤º `route_from_router_invalid_key`

**åŸå› **:
1. è·¯ç”±è§„åˆ™æœªé…ç½®
2. æ„å›¾åç§°ä¸åŒ¹é…

**è§£å†³**:
```python
# æ£€æŸ¥ intent_orchestrator_app.py
route_map = {
    "general-chat": "general-chat",  # ç¡®ä¿å­˜åœ¨
}

# æ£€æŸ¥ registry.py
handlers = {
    "general-chat": general_chat_handler,  # ç¡®ä¿å­˜åœ¨
}
```

### é—®é¢˜2: LLMè¿”å›ç©ºå›ç­”

**ç—‡çŠ¶**: `answer=""` æˆ– `answer=None`

**åŸå› **:
1. ç³»ç»Ÿæç¤ºè¯è¿‡é•¿å¯¼è‡´tokenè€—å°½
2. temperatureè®¾ç½®ä¸å½“
3. APIè°ƒç”¨å¤±è´¥

**è§£å†³**:
```python
# 1. æ£€æŸ¥max_tokensè®¾ç½®
max_tokens=500,  # ç¡®ä¿è¶³å¤Ÿ

# 2. æ£€æŸ¥temperature
temperature=0.7,  # 0.0-1.0èŒƒå›´å†…

# 3. æ·»åŠ å¼‚å¸¸å¤„ç†
try:
    response = self.llm_client.chat.completions.create(...)
    answer = response.choices[0].message.content.strip()
except Exception as e:
    logger.error("llm_error", error=str(e))
    answer = FALLBACK_ANSWER  # å…œåº•å›ç­”
```

### é—®é¢˜3: æ„å›¾è¯†åˆ«ä¸ºUNKNOWNè€ŒéGENERAL_CHAT

**ç—‡çŠ¶**: å³ä½¿ä¿®æ”¹äº†æç¤ºè¯ï¼Œä»è¯†åˆ«ä¸ºUNKNOWN

**åŸå› **:
1. æç¤ºè¯æœªç”Ÿæ•ˆï¼ˆç¼“å­˜é—®é¢˜ï¼‰
2. LLMæ¨¡å‹æœªæ›´æ–°
3. confidenceé˜ˆå€¼è¿‡é«˜

**è§£å†³**:
```bash
# 1. é‡å¯æœåŠ¡æ¸…é™¤ç¼“å­˜
kill $(cat temp/uvicorn.pid)
./scripts/dev-run.sh

# 2. æ£€æŸ¥LLMæç¤ºè¯æ˜¯å¦æ­£ç¡®åŠ è½½
grep "GENERAL_CHAT" src/emergency_agents/intent/providers/llm.py

# 3. é™ä½confidenceé˜ˆå€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
thresholds = IntentThresholds(
    confidence=0.6,  # ä»0.7é™è‡³0.6
    margin=0.2,      # ä»0.3é™è‡³0.2
)
```

---

## å‚è€ƒèµ„æ–™

### å†…éƒ¨æ–‡æ¡£

- [CLAUDE.md](../../CLAUDE.md) - é¡¹ç›®å¼€å‘è§„èŒƒ
- [AGENTS.md](../../AGENTS.md) - 4é˜¶æ®µäº¤äº’æµç¨‹
- [QUICK-START.md](../../QUICK-START.md) - å¿«é€Ÿå¼€å§‹æŒ‡å—
- [æ„å›¾è¯†åˆ«ç³»ç»Ÿæ–‡æ¡£](../æ„å›¾è¯†åˆ«/README.md)

### å¤–éƒ¨èµ„æº

- [LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [æ™ºè°±GLM-4æ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/chat)

### ç›¸å…³è®ºæ–‡

- ReAct: Synergizing Reasoning and Acting in Language Models
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
- LangGraph: A Framework for Multi-Agent Applications

---

## å˜æ›´å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | å˜æ›´å†…å®¹ |
|------|------|------|---------|
| v1.0 | 2025-11-06 | msq | åˆå§‹ç‰ˆæœ¬ï¼Œå®ç°é€šç”¨å¯¹è¯Handler |

---

## é™„å½•

### A. å®Œæ•´æ–‡ä»¶åˆ—è¡¨

```
emergency-agents-langgraph/
â”œâ”€â”€ src/emergency_agents/
â”‚   â”œâ”€â”€ intent/
â”‚   â”‚   â”œâ”€â”€ schemas.py              # æ§½ä½å®šä¹‰ï¼ˆå·²ä¿®æ”¹ï¼‰
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py         # Handlerå¯¼å‡ºï¼ˆå·²ä¿®æ”¹ï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ general_chat.py     # å¯¹è¯Handlerï¼ˆæ–°å¢ï¼‰âœ¨
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â””â”€â”€ llm.py              # LLMæç¤ºè¯ï¼ˆå·²ä¿®æ”¹ï¼‰
â”‚   â”‚   â”œâ”€â”€ unified_intent.py        # ç»Ÿä¸€æ„å›¾ï¼ˆå·²ä¿®æ”¹ï¼‰
â”‚   â”‚   â””â”€â”€ registry.py              # Handleræ³¨å†Œï¼ˆå·²ä¿®æ”¹ï¼‰
â”‚   â””â”€â”€ graph/
â”‚       â””â”€â”€ intent_orchestrator_app.py  # è·¯ç”±è§„åˆ™ï¼ˆå·²ä¿®æ”¹ï¼‰
â”œâ”€â”€ test_general_chat.py            # æµ‹è¯•è„šæœ¬ï¼ˆæ–°å¢ï¼‰âœ¨
â””â”€â”€ docs/å­å›¾åŠŸèƒ½å¼€å‘/
    â””â”€â”€ å¯¹è¯handler.md              # æœ¬æ–‡æ¡£ï¼ˆæ–°å¢ï¼‰âœ¨
```

### B. ç›¸å…³Issueå’ŒPR

- Issue #XXX: ç”¨æˆ·åé¦ˆå¯¹è¯åŠŸèƒ½ç¼ºå¤±
- PR #XXX: å®ç°é€šç”¨å¯¹è¯Handler
- Commit: `feat: add general chat handler with professional prompts`

---

**æ–‡æ¡£ç»“æŸ** ğŸ“„

å¦‚æœ‰ç–‘é—®æˆ–å»ºè®®ï¼Œè¯·è”ç³» msq æˆ–æäº¤Issueã€‚
