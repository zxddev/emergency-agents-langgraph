# GLM-4.6 æ¨¡å‹ API Key é…ç½®è¯´æ˜

## ğŸ” å½“å‰ä½¿ç”¨çš„API Key

### glm-4.6 æ¨¡å‹ä½¿ç”¨çš„ Key

**API Key**: `854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8`

**Keyåç§°**: `LLM_KEY_PRIMARY` (ä¸»é€šé“Key)

**Base URL**: `https://open.bigmodel.cn/api/paas/v4`

---

## ğŸ“‹ é…ç½®åŠ è½½æµç¨‹

### 1. å¯åŠ¨è„šæœ¬åŠ è½½é¡ºåº

**æ–‡ä»¶**: `scripts/dev-run.sh`

```bash
# ç¬¬19-20è¡Œ
source config/llm_keys.env    # å…ˆåŠ è½½Keyå®šä¹‰
source config/dev.env          # å†åŠ è½½é…ç½®ï¼ˆä½¿ç”¨Keyå˜é‡ï¼‰
```

---

### 2. Keyå®šä¹‰æ–‡ä»¶

**æ–‡ä»¶**: `config/llm_keys.env` (ç¬¬11è¡Œ)

```bash
LLM_KEY_PRIMARY=854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8
```

**è¯´æ˜**: è¿™æ˜¯ä¸»é€šé“Keyï¼Œç”¨äºå®æ—¶æ„å›¾è¯†åˆ«ã€æ–¹æ¡ˆç”Ÿæˆç­‰æ ¸å¿ƒåŠŸèƒ½

---

### 3. é…ç½®å¼•ç”¨

**æ–‡ä»¶**: `config/dev.env` (ç¬¬21è¡Œ)

```bash
OPENAI_API_KEY=${LLM_KEY_PRIMARY}
```

**è¯´æ˜**: ä½¿ç”¨Shellå˜é‡å±•å¼€ï¼Œå°† `LLM_KEY_PRIMARY` çš„å€¼èµ‹ç»™ `OPENAI_API_KEY`

---

### 4. ä»£ç ä½¿ç”¨

**æ–‡ä»¶**: `src/emergency_agents/api/reports.py` (ç¬¬382-388è¡Œ)

```python
llm_client = get_openai_client(cfg)  # ä½¿ç”¨ cfg.openai_api_key

completion = llm_client.chat.completions.create(
    model="glm-4.6",  # ç¡¬ç¼–ç ä½¿ç”¨ glm-4.6 æ¨¡å‹
    # ...
)
```

**æ–‡ä»¶**: `src/emergency_agents/config.py` (ç¬¬107è¡Œ)

```python
openai_api_key = os.getenv("OPENAI_API_KEY", "dummy")
```

---

## ğŸ”‘ æ‰€æœ‰å¯ç”¨çš„API Key

**æ–‡ä»¶**: `config/llm_keys.env`

| Keyåç§° | å€¼ | ç”¨é€” |
|---------|-----|------|
| `LLM_KEY_PRIMARY` | `854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8` | **ä¸»é€šé“** - å®æ—¶æ„å›¾ã€æ–¹æ¡ˆç”Ÿæˆã€æŠ¥å‘Šç”Ÿæˆ |
| `LLM_KEY_SECONDARY` | `b33ffec2c17644bea471bf4071a55a25.9svQ5VbP36wrAdMF` | **ç¬¬äºŒé€šé“** - ç†”æ–­å¤‡ç”¨ |
| `LLM_KEY_TERTIARY` | `9c63e91657be424995b84bcd49646ef5.0pr9fRxzz2TLIZ8t` | **ç¬¬ä¸‰é€šé“** - è¿›ä¸€æ­¥åˆ†æ‘Šé™æµ |
| `LLM_KEY_LEGACY` | `3116c00e0d32439e90c86a2bc12167ac.58CvdyQCLJyrKf5S` | **å…œåº•é€šé“** - å…¨éƒ¨ä¸å¯ç”¨æ—¶ä½¿ç”¨ |
| `LLM_KEY_RECON` | `9c63e91657be424995b84bcd49646ef5.0pr9fRxzz2TLIZ8t` | **ä¾¦å¯Ÿé€šé“** - åŒTERTIARY |
| `MEM0_OPENAI_KEY` | `55be5042f7e44535a62e24721b28d039.27obcTHfO2ULZiQl` | **Mem0ä¸“ç”¨** - é¿å…ä¸ä¸»æµç¨‹æŠ¢é¢åº¦ |

---

## ğŸ¯ æ•‘æ´è¯„ä¼°æŠ¥å‘ŠAPIå…·ä½“ä½¿ç”¨æƒ…å†µ

### å½“å‰é…ç½®

```
æŠ¥å‘Šç”Ÿæˆæ¥å£: POST /reports/rescue-assessment
æ¨¡å‹: glm-4.6
API Key: 854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8 (LLM_KEY_PRIMARY)
Base URL: https://open.bigmodel.cn/api/paas/v4
```

### è°ƒç”¨é“¾è·¯

```
1. ç”¨æˆ·è¯·æ±‚ â†’ POST /reports/rescue-assessment

2. reports.py:382
   llm_client = get_openai_client(cfg)

3. llm/client.py:83-86
   cfg = AppConfig.load_from_env()
   manager = LLMEndpointManager.from_config(cfg)

4. config.py:107
   openai_api_key = os.getenv("OPENAI_API_KEY")
   # æ­¤æ—¶ OPENAI_API_KEY = "854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8"

5. reports.py:387-388
   completion = llm_client.chat.completions.create(
       model="glm-4.6",  # ç¡¬ç¼–ç æ¨¡å‹å
       ...
   )
```

---

## ğŸ”„ æ•…éšœè½¬ç§»æœºåˆ¶

### LLM Endpoint Manager

**é…ç½®**: `config/dev.env` (ç¬¬35è¡Œ)

```bash
LLM_ENDPOINTS=[
  {"name":"glm-key-a","base_url":"https://open.bigmodel.cn/api/paas/v4","api_key":"${LLM_KEY_PRIMARY}","priority":150},
  {"name":"glm-key-b","base_url":"https://open.bigmodel.cn/api/paas/v4","api_key":"${LLM_KEY_SECONDARY}","priority":140},
  {"name":"glm-key-c","base_url":"https://open.bigmodel.cn/api/paas/v4","api_key":"${LLM_KEY_TERTIARY}","priority":130},
  {"name":"glm-key-legacy","base_url":"https://open.bigmodel.cn/api/paas/v4","api_key":"${LLM_KEY_LEGACY}","priority":120},
  {"name":"intranet-gateway","base_url":"http://192.168.31.40/v1","api_key":"${LLM_KEY_PRIMARY}","priority":90}
]
```

### ä¼˜å…ˆçº§é¡ºåº

1. **ä¼˜å…ˆçº§150** - glm-key-a (LLM_KEY_PRIMARY) â† **å½“å‰ä½¿ç”¨**
2. ä¼˜å…ˆçº§140 - glm-key-b (LLM_KEY_SECONDARY)
3. ä¼˜å…ˆçº§130 - glm-key-c (LLM_KEY_TERTIARY)
4. ä¼˜å…ˆçº§120 - glm-key-legacy (LLM_KEY_LEGACY)
5. ä¼˜å…ˆçº§90 - intranet-gateway (å†…ç½‘ç½‘å…³)

**æ•…éšœè½¬ç§»**: å½“ä¸»Keyå¤±è´¥æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æ¬¡ä¼˜å…ˆçº§Key

---

## ğŸ”§ å¦‚ä½•ä¿®æ”¹API Key

### æ–¹å¼1ï¼šä¿®æ”¹ä¸»Keyï¼ˆæ¨èï¼‰

**æ–‡ä»¶**: `config/llm_keys.env`

```bash
# ä¿®æ”¹ç¬¬11è¡Œ
LLM_KEY_PRIMARY=æ–°çš„API_KEY
```

**å½±å“èŒƒå›´**: æ‰€æœ‰ä½¿ç”¨ PRIMARY Key çš„æœåŠ¡

**é‡å¯æœåŠ¡**: å¿…é¡»

---

### æ–¹å¼2ï¼šä¸ºæŠ¥å‘ŠAPIæŒ‡å®šä¸“ç”¨Key

**æ–‡ä»¶**: `config/llm_keys.env` (æ–°å¢)

```bash
LLM_KEY_REPORTS=æ–°çš„ä¸“ç”¨KEY
```

**æ–‡ä»¶**: `config/dev.env` (æ–°å¢)

```bash
REPORTS_API_KEY=${LLM_KEY_REPORTS}
```

**æ–‡ä»¶**: `src/emergency_agents/api/reports.py` (ä¿®æ”¹)

```python
# ç¬¬382è¡Œä¿®æ”¹ä¸ºï¼š
from openai import OpenAI

llm_client = OpenAI(
    base_url="https://open.bigmodel.cn/api/paas/v4",
    api_key=os.getenv("REPORTS_API_KEY")
)
```

**ä¼˜ç‚¹**:
- ç‹¬ç«‹é…ç½®ï¼Œä¸å½±å“å…¶ä»–æœåŠ¡
- å¯ä»¥ä½¿ç”¨ä¸åŒçš„é™é¢é…ç½®
- ä¾¿äºæˆæœ¬æ ¸ç®—

---

### æ–¹å¼3ï¼šä¸´æ—¶æµ‹è¯•ï¼ˆä¸æ¨èç”Ÿäº§ä½¿ç”¨ï¼‰

```bash
# ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="ä¸´æ—¶æµ‹è¯•KEY"

# å¯åŠ¨æœåŠ¡
./scripts/dev-run.sh
```

---

## ğŸ“Š Keyä½¿ç”¨ç›‘æ§

### æŸ¥çœ‹å½“å‰ä½¿ç”¨çš„Key

```bash
# æŸ¥çœ‹ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# æŸ¥çœ‹å®é™…åŠ è½½çš„é…ç½®
grep OPENAI_API_KEY config/dev.env

# æŸ¥çœ‹Keyå®šä¹‰
grep LLM_KEY_PRIMARY config/llm_keys.env
```

### æ™ºè°±AIæ§åˆ¶å°

1. ç™»å½• [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
2. è¿›å…¥"æ§åˆ¶å°" â†’ "API Keys"
3. æŸ¥çœ‹ `854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8` çš„ä½¿ç”¨æƒ…å†µï¼š
   - è°ƒç”¨æ¬¡æ•°
   - Tokenæ¶ˆè€—
   - ä½™é¢/é…é¢
   - é”™è¯¯ç‡

---

## âš ï¸ å®‰å…¨æ³¨æ„äº‹é¡¹

### 1. Keyä¿æŠ¤

- âœ… `config/llm_keys.env` å·²åŠ å…¥ `.gitignore`
- âœ… ä¸ä¼šæäº¤åˆ°Gitä»“åº“
- âš ï¸ ä¸è¦åœ¨æ—¥å¿—ä¸­æ‰“å°å®Œæ•´Key
- âš ï¸ ä¸è¦åœ¨å…¬å¼€æ–‡æ¡£ä¸­æš´éœ²Key

### 2. Keyè½®æ¢

å»ºè®®å®šæœŸï¼ˆå¦‚æ¯å­£åº¦ï¼‰è½®æ¢API Keyï¼š

```bash
# 1. åœ¨æ™ºè°±AIæ§åˆ¶å°ç”Ÿæˆæ–°Key
# 2. æ›´æ–° llm_keys.env
# 3. é‡å¯æœåŠ¡
# 4. éªŒè¯æœåŠ¡æ­£å¸¸
# 5. åˆ é™¤æ—§Key
```

### 3. æœ€å°æƒé™åŸåˆ™

- ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ç‹¬ç«‹Key
- å¼€å‘/æµ‹è¯•ç¯å¢ƒå…±äº«Key
- é™åˆ¶å•ä¸ªKeyçš„è°ƒç”¨é€Ÿç‡
- è®¾ç½®æ¶ˆè´¹é¢„è­¦

---

## ğŸ§ª éªŒè¯é…ç½®

### æµ‹è¯•API Keyæ˜¯å¦æœ‰æ•ˆ

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨curlç›´æ¥æµ‹è¯•
curl -X POST https://open.bigmodel.cn/api/paas/v4/chat/completions \
  -H "Authorization: Bearer 854f678ad24645b89b4bc27b94d29b58.Ne5Ep2W60GDPT7B8" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "glm-4.6",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }'

# æ–¹æ³•2ï¼šè°ƒç”¨æŠ¥å‘ŠAPIæµ‹è¯•
curl -X POST http://localhost:8000/reports/rescue-assessment \
  -H "Content-Type: application/json" \
  -d @tests/fixtures/rescue_assessment_minimal_input.json

# æ–¹æ³•3ï¼šæŸ¥çœ‹æœåŠ¡æ—¥å¿—
tail -f temp/server.log | grep -i "openai\|glm"
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ç¡®è®¤å½“å‰ä½¿ç”¨çš„Keyï¼Ÿ

```bash
# æŸ¥çœ‹å¯åŠ¨è„šæœ¬åŠ è½½çš„ç¯å¢ƒå˜é‡
source config/llm_keys.env
source config/dev.env
echo "å½“å‰ä½¿ç”¨çš„Key: $OPENAI_API_KEY"
```

### Q2: Keyå¤±æ•ˆæ€ä¹ˆåŠï¼Ÿ

1. æ£€æŸ¥æ™ºè°±AIæ§åˆ¶å°ï¼Œç¡®è®¤Keyæ˜¯å¦è¿‡æœŸ
2. æ£€æŸ¥ä½™é¢/é…é¢æ˜¯å¦å……è¶³
3. æ›´æ¢åˆ°å¤‡ç”¨Keyï¼ˆLLM_KEY_SECONDARYï¼‰
4. æŸ¥çœ‹æœåŠ¡æ—¥å¿—çš„é”™è¯¯ä¿¡æ¯

### Q3: å¦‚ä½•åˆ‡æ¢åˆ°å…¶ä»–Keyï¼Ÿ

```bash
# ä¿®æ”¹ config/dev.env ç¬¬21è¡Œ
# ä»:
OPENAI_API_KEY=${LLM_KEY_PRIMARY}

# æ”¹ä¸º:
OPENAI_API_KEY=${LLM_KEY_SECONDARY}

# é‡å¯æœåŠ¡
pkill -f uvicorn
./scripts/dev-run.sh
```

### Q4: ä¸ºä»€ä¹ˆæ—¥å¿—ä¸­çœ‹ä¸åˆ°å®Œæ•´Keyï¼Ÿ

ä¸ºäº†å®‰å…¨ï¼Œæ—¥å¿—ä¸­åªæ˜¾ç¤ºKeyçš„å‰8ä½å’Œå4ä½ï¼š

```
ä½¿ç”¨Key: 854f678a...7B8
```

---

## ğŸ“… ç»´æŠ¤è®°å½•

| æ—¥æœŸ | æ“ä½œ | æ“ä½œäºº |
|------|------|--------|
| 2025-11-03 | ç¡®è®¤æ•‘æ´è¯„ä¼°APIä½¿ç”¨ LLM_KEY_PRIMARY | Claude Code |
| 2025-11-03 | åˆ›å»ºæœ¬é…ç½®è¯´æ˜æ–‡æ¡£ | Claude Code |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-03
**ç»´æŠ¤è€…**: AIåº”æ€¥å¤§è„‘é¡¹ç›®ç»„
